{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layout.json: Differences found:\n",
      "{'dictionary_item_added': [root['legend'], root['annotations']]}\n",
      "config.json: Files are identical\n",
      "data.json: Differences found:\n",
      "{'values_changed': {'root[3]': {'new_value': {'type': 'scatterpolar', 'r': [20, 25, 22, 18, 30, 28, 20, 18], 'theta': ['Cardio', 'Strength', 'Flexibility', 'Endurance', 'Nutrition', 'Sleep', 'Hydration', 'Mental Health'], 'mode': 'lines+markers', 'name': 'Week 4', 'marker': {'size': 8, 'color': 'purple'}, 'line': {'color': 'purple', 'width': 2}}, 'old_value': {'type': 'scatterpolar', 'r': [30, 25, 20, 30, 35, 30, 25, 25], 'theta': ['Nutrition', 'Sleep', 'Hydration', 'Endurance', 'Flexibility', 'Strength', 'Cardio', 'Mental Health'], 'mode': 'lines+markers', 'name': 'Week 4', 'marker': {'size': 8, 'color': 'red'}, 'line': {'color': 'red', 'width': 2}}}, 'root[0]': {'new_value': {'type': 'scatterpolar', 'r': [15, 20, 18, 12, 25, 22, 16, 14], 'theta': ['Cardio', 'Strength', 'Flexibility', 'Endurance', 'Nutrition', 'Sleep', 'Hydration', 'Mental Health'], 'mode': 'lines+markers', 'name': 'Week 1', 'marker': {'size': 8, 'color': 'blue'}, 'line': {'color': 'blue', 'width': 2}}, 'old_value': {'type': 'scatterpolar', 'r': [15, 10, 5, 10, 15, 10, 5, 10], 'theta': ['Nutrition', 'Sleep', 'Hydration', 'Endurance', 'Flexibility', 'Strength', 'Cardio', 'Mental Health'], 'mode': 'lines+markers', 'name': 'Week 1', 'marker': {'size': 8, 'color': 'blue'}, 'line': {'color': 'blue', 'width': 2}}}, 'root[1]': {'new_value': {'type': 'scatterpolar', 'r': [18, 22, 20, 15, 28, 25, 18, 16], 'theta': ['Cardio', 'Strength', 'Flexibility', 'Endurance', 'Nutrition', 'Sleep', 'Hydration', 'Mental Health'], 'mode': 'lines+markers', 'name': 'Week 2', 'marker': {'size': 8, 'color': 'green'}, 'line': {'color': 'green', 'width': 2}}, 'old_value': {'type': 'scatterpolar', 'r': [20, 15, 10, 15, 20, 20, 10, 15], 'theta': ['Nutrition', 'Sleep', 'Hydration', 'Endurance', 'Flexibility', 'Strength', 'Cardio', 'Mental Health'], 'mode': 'lines+markers', 'name': 'Week 2', 'marker': {'size': 8, 'color': 'green'}, 'line': {'color': 'green', 'width': 2}}}, 'root[2]': {'new_value': {'type': 'scatterpolar', 'r': [16, 18, 15, 10, 20, 18, 12, 10], 'theta': ['Cardio', 'Strength', 'Flexibility', 'Endurance', 'Nutrition', 'Sleep', 'Hydration', 'Mental Health'], 'mode': 'lines+markers', 'name': 'Week 3', 'marker': {'size': 8, 'color': 'red'}, 'line': {'color': 'red', 'width': 2}}, 'old_value': {'type': 'scatterpolar', 'r': [25, 20, 15, 25, 30, 25, 15, 20], 'theta': ['Nutrition', 'Sleep', 'Hydration', 'Endurance', 'Flexibility', 'Strength', 'Cardio', 'Mental Health'], 'mode': 'lines+markers', 'name': 'Week 3', 'marker': {'size': 8, 'color': 'purple'}, 'line': {'color': 'purple', 'width': 2}}}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from deepdiff import DeepDiff\n",
    "\n",
    "# Paths to the directories\n",
    "folder1 = 'D:\\Dataset Creation\\json_matching\\gpt4output'\n",
    "folder2 = 'D:\\Dataset Creation\\json_matching\\ground_truth_radar chart'\n",
    "\n",
    "# List all JSON files in both directories\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith('.json')]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith('.json')]\n",
    "\n",
    "# Ensure both directories have the same JSON file names for comparison\n",
    "common_files = set(files1).intersection(files2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to compare JSON files\n",
    "def compare_json_files(file1_path, file2_path):\n",
    "    with open(file1_path, 'r') as file1, open(file2_path, 'r') as file2:\n",
    "        json1 = json.load(file1)\n",
    "        json2 = json.load(file2)\n",
    "        \n",
    "        # Compare JSON using DeepDiff\n",
    "        diff = DeepDiff(json1, json2, ignore_order=True)\n",
    "        \n",
    "        # Return differences or indicate similarity\n",
    "        if not diff:\n",
    "            return f\"{os.path.basename(file1_path)}: Files are identical\"\n",
    "        else:\n",
    "            return f\"{os.path.basename(file1_path)}: Differences found:\\n{diff}\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(json1, json2):\n",
    "    return 100 if json1 == json2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from deepdiff import DeepDiff\n",
    "\n",
    "# Function to load JSON files\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Function to compare two JSON files using DeepDiff for complex structures\n",
    "def compare_json_files(file1_path, file2_path):\n",
    "    json1 = load_json(file1_path)\n",
    "    json2 = load_json(file2_path)\n",
    "    \n",
    "    # Perform deep comparison with DeepDiff\n",
    "    diff = DeepDiff(json1, json2, ignore_order=True, report_repetition=True, view='tree')\n",
    "    return diff\n",
    "\n",
    "# Exact match check (ignores list order)\n",
    "def exact_match(file1_path, file2_path):\n",
    "    json1 = load_json(file1_path)\n",
    "    json2 = load_json(file2_path)\n",
    "    return json1 == json2\n",
    "\n",
    "# Key match function that handles list of dictionaries\n",
    "def key_match(file1_path, file2_path):\n",
    "    json1 = load_json(file1_path)\n",
    "    json2 = load_json(file2_path)\n",
    "\n",
    "    if isinstance(json1, list) and isinstance(json2, list):\n",
    "        # For list of objects, collect all keys in both lists\n",
    "        keys1 = set(k for d in json1 if isinstance(d, dict) for k in d.keys())\n",
    "        keys2 = set(k for d in json2 if isinstance(d, dict) for k in d.keys())\n",
    "    else:\n",
    "        # If not lists, assume they are dicts\n",
    "        keys1 = set(json1.keys())\n",
    "        keys2 = set(json2.keys())\n",
    "\n",
    "    total_keys = len(keys1.union(keys2))\n",
    "    common_keys = len(keys1.intersection(keys2))\n",
    "\n",
    "    return {\"common_keys\": common_keys, \"total_keys\": total_keys, \"key_match_percentage\": (common_keys / total_keys) * 100}\n",
    "\n",
    "# Value match function to handle list of objects\n",
    "def value_match(file1_path, file2_path):\n",
    "    json1 = load_json(file1_path)\n",
    "    json2 = load_json(file2_path)\n",
    "\n",
    "    common_values = 0\n",
    "    total_values = 0\n",
    "\n",
    "    if isinstance(json1, list) and isinstance(json2, list):\n",
    "        # Compare values within lists of dicts\n",
    "        for d1, d2 in zip(json1, json2):\n",
    "            if isinstance(d1, dict) and isinstance(d2, dict):\n",
    "                common_values += len(set(d1.values()).intersection(set(d2.values())))\n",
    "                total_values += len(set(d1.values()).union(set(d2.values())))\n",
    "\n",
    "    value_match_percentage = (common_values / total_values) * 100 if total_values else 0\n",
    "    return {\"common_values\": common_values, \"total_values\": total_values, \"value_match_percentage\": value_match_percentage}\n",
    "\n",
    "# Other functions for cosine similarity, structural similarity, etc. will remain similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def key_match(file1_path, file2_path):\n",
    "    # Open and load JSON from both files\n",
    "    with open(file1_path, 'r') as file1, open(file2_path, 'r') as file2:\n",
    "        json1 = json.load(file1)\n",
    "        json2 = json.load(file2)\n",
    "\n",
    "    # Ensure the loaded files are dictionaries\n",
    "    if not isinstance(json1, dict) or not isinstance(json2, dict):\n",
    "        raise ValueError(\"One of the JSON objects is not a dictionary\")\n",
    "    \n",
    "    # Extract the keys from both JSON files\n",
    "    keys1 = set(json1.keys())\n",
    "    keys2 = set(json2.keys())\n",
    "    \n",
    "    # Compare the keys\n",
    "    total_keys = len(keys1.union(keys2))\n",
    "    matching_keys = len(keys1.intersection(keys2))\n",
    "    \n",
    "    # Return the ratio of matching keys\n",
    "    if total_keys == 0:\n",
    "        return 1.0  # If no keys in either, they match perfectly\n",
    "    return matching_keys / total_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def value_match(file1_path, file2_path):\n",
    "    # Open and load JSON from both files\n",
    "    with open(file1_path, 'r') as file1, open(file2_path, 'r') as file2:\n",
    "        json1 = json.load(file1)\n",
    "        json2 = json.load(file2)\n",
    "\n",
    "    # Ensure the loaded files are dictionaries\n",
    "    if not isinstance(json1, dict) or not isinstance(json2, dict):\n",
    "        raise ValueError(\"One of the JSON objects is not a dictionary\")\n",
    "    \n",
    "    # Find common keys\n",
    "    common_keys = set(json1.keys()).intersection(json2.keys())\n",
    "    total_common_keys = len(common_keys)\n",
    "\n",
    "    if total_common_keys == 0:\n",
    "        return 0.0  # No common keys, so no value match\n",
    "\n",
    "    # Compare values of common keys\n",
    "    matching_values = sum(1 for key in common_keys if json1[key] == json2[key])\n",
    "\n",
    "    # Return the ratio of matching values over total common keys\n",
    "    return matching_values / total_common_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structural_similarity(json1, json2):\n",
    "    diff = DeepDiff(json1, json2, ignore_order=True)\n",
    "    total_elements = len(json1) + len(json2)\n",
    "    mismatched_elements = len(diff)\n",
    "    \n",
    "    if total_elements == 0:\n",
    "        return 100\n",
    "    \n",
    "    return ((total_elements - mismatched_elements) / total_elements) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_values(str1, str2):\n",
    "    count_vectorizer = CountVectorizer().fit_transform([str1, str2])\n",
    "    vectors = count_vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0][1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def numerical_difference(file1_path, file2_path):\n",
    "    # Open and load JSON from both files\n",
    "    with open(file1_path, 'r') as file1, open(file2_path, 'r') as file2:\n",
    "        json1 = json.load(file1)\n",
    "        json2 = json.load(file2)\n",
    "\n",
    "    # Ensure both loaded JSONs are dictionaries\n",
    "    if not isinstance(json1, dict) or not isinstance(json2, dict):\n",
    "        raise ValueError(\"One of the JSON objects is not a dictionary\")\n",
    "\n",
    "    # Find common keys\n",
    "    common_keys = set(json1.keys()).intersection(json2.keys())\n",
    "    total_common_keys = len(common_keys)\n",
    "\n",
    "    if total_common_keys == 0:\n",
    "        return 0.0  # No common keys, so no comparison possible\n",
    "\n",
    "    # Sum up the numerical differences for all common keys that hold numerical values\n",
    "    total_difference = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for key in common_keys:\n",
    "        if isinstance(json1[key], (int, float)) and isinstance(json2[key], (int, float)):\n",
    "            total_difference += abs(json1[key] - json2[key])\n",
    "            count += 1\n",
    "\n",
    "    # If no numeric comparisons were made, return 0\n",
    "    if count == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Return the average numerical difference\n",
    "    return total_difference / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def levenshtein_similarity(str1, str2):\n",
    "    distance = Levenshtein.distance(str1, str2)\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    \n",
    "    if max_len == 0:\n",
    "        return 100\n",
    "    return (1 - distance / max_len) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    \n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    \n",
    "    if union == 0:\n",
    "        return 100\n",
    "    return (intersection / union) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing D:\\Dataset Creation\\json_matching\\gpt4output\\layout.json and D:\\Dataset Creation\\json_matching\\ground_truth_radar chart\\layout.json\n",
      "{'dictionary_item_added': [<root['legend'] t1:not present, t2:{'x': 0.8, '...}>, <root['annotations'] t1:not present, t2:[{'x': 'Card...]>]}\n",
      "False\n",
      "{'common_keys': 2, 'total_keys': 4, 'key_match_percentage': 50.0}\n",
      "{'common_values': 0, 'total_values': 0, 'value_match_percentage': 0}\n",
      "99.20634920634922\n",
      "77.15167498104596\n",
      "0.0\n",
      "71.42857142857143\n",
      "88.46153846153845\n",
      "Comparing D:\\Dataset Creation\\json_matching\\gpt4output\\config.json and D:\\Dataset Creation\\json_matching\\ground_truth_radar chart\\config.json\n",
      "{}\n",
      "True\n",
      "{'common_keys': 3, 'total_keys': 3, 'key_match_percentage': 100.0}\n",
      "{'common_values': 0, 'total_values': 0, 'value_match_percentage': 0}\n",
      "99.20634920634922\n",
      "77.15167498104596\n",
      "0.0\n",
      "71.42857142857143\n",
      "88.0\n",
      "Comparing D:\\Dataset Creation\\json_matching\\gpt4output\\data.json and D:\\Dataset Creation\\json_matching\\ground_truth_radar chart\\data.json\n",
      "{'iterable_item_removed': [<root[0] t1:{'type': 'sc...}, t2:not present>, <root[1] t1:{'type': 'sc...}, t2:not present>, <root[2] t1:{'type': 'sc...}, t2:not present>, <root[3] t1:{'type': 'sc...}, t2:not present>], 'iterable_item_added': [<root[0] t1:not present, t2:{'type': 'sc...}>, <root[1] t1:not present, t2:{'type': 'sc...}>, <root[2] t1:not present, t2:{'type': 'sc...}>, <root[3] t1:not present, t2:{'type': 'sc...}>]}\n",
      "False\n",
      "{'common_keys': 7, 'total_keys': 7, 'key_match_percentage': 100.0}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__________________________________________________________\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(key_match_result)\n\u001b[1;32m---> 32\u001b[0m value_match_result \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile1_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile2_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__________________________________________________________\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue_match_result: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[29], line 55\u001b[0m, in \u001b[0;36mvalue_match\u001b[1;34m(file1_path, file2_path)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d1, d2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(json1, json2):\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(d1, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(d2, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m---> 55\u001b[0m             common_values \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;28mset\u001b[39m(d2\u001b[38;5;241m.\u001b[39mvalues())))\n\u001b[0;32m     56\u001b[0m             total_values \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(d1\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;28mset\u001b[39m(d2\u001b[38;5;241m.\u001b[39mvalues())))\n\u001b[0;32m     58\u001b[0m value_match_percentage \u001b[38;5;241m=\u001b[39m (common_values \u001b[38;5;241m/\u001b[39m total_values) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total_values \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Compare each JSON file in both folders\n",
    "for file_name in common_files:\n",
    "    file1_path = os.path.join(folder1, file_name)\n",
    "    file2_path = os.path.join(folder2, file_name)\n",
    "\n",
    "    print(f\"Comparing {file1_path} and {file2_path}\")\n",
    "    \n",
    "    with open('D:\\Dataset Creation\\json_matching/result.txt', 'a') as f:\n",
    "        f.write(f\"Comparing {file1_path} and {file2_path}\\n\")\n",
    "        DeepDiff_result = compare_json_files(file1_path, file2_path)\n",
    "        f.write(\"__________________________________________________________\\n\")\n",
    "        f.write(\"DeepDiff: \\n\")\n",
    "        f.write(str(DeepDiff_result) + '\\n')\n",
    "        f.write(\"__________________________________________________________\\n\\n\\n\")\n",
    "        print(DeepDiff_result)\n",
    "\n",
    "        exact_match_result = exact_match(file1_path, file2_path)\n",
    "\n",
    "        f.write(\"__________________________________________________________\\n\")\n",
    "        f.write(\"exact_match_result: \\n\")\n",
    "        f.write(str(exact_match_result) + '\\n')\n",
    "        f.write(\"__________________________________________________________\\n\\n\\n\")\n",
    "        print(exact_match_result)\n",
    "\n",
    "        key_match_result = key_match(file1_path, file2_path)\n",
    "        f.write(\"__________________________________________________________\\n\")\n",
    "        f.write(\"key_match_result: \\n\")\n",
    "        f.write(str(key_match_result) + '\\n')\n",
    "        f.write(\"__________________________________________________________\\n\\n\\n\")\n",
    "        print(key_match_result)\n",
    "\n",
    "        value_match_result = value_match(file1_path, file2_path)\n",
    "        f.write(\"__________________________________________________________\\n\")\n",
    "        f.write(\"value_match_result: \\n\")\n",
    "        f.write(str(value_match_result) + '\\n')\n",
    "        f.write(\"__________________________________________________________\\n\\n\\n\")\n",
    "        print(value_match_result)\n",
    "\n",
    "        structural_similarity_result = structural_similarity(file1_path, file2_path)\n",
    "        f.write(\"__________________________________________________________\\n\")\n",
    "        f.write(\"structural_similarity_result: \\n\")\n",
    "        f.write(str(structural_similarity_result) + '\\n')\n",
    "        f.write(\"__________________________________________________________\\n\\n\\n\")\n",
    "        print(structural_similarity_result)\n",
    "\n",
    "        cosine_similarity_values_result = cosine_similarity_values(file1_path, file2_path)\n",
    "        f.write(\"__________________________________________________________\\n\")\n",
    "        f.write(\"cosine_similarity_values_result: \\n\")\n",
    "        f.write(str(cosine_similarity_values_result) + '\\n')\n",
    "        f.write(\"__________________________________________________________\\n\\n\\n\")\n",
    "        print(cosine_similarity_values_result)\n",
    "\n",
    "        numerical_difference_result = numerical_difference(file1_path, file2_path)\n",
    "        f.write(\"__________________________________________________________\\n\")\n",
    "        f.write(\"numerical_difference_result: \\n\")\n",
    "        f.write(str(numerical_difference_result) + '\\n')\n",
    "        f.write(\"__________________________________________________________\\n\\n\\n\")\n",
    "        print(numerical_difference_result)\n",
    "\n",
    "        levenshtein_similarity_result = levenshtein_similarity(file1_path, file2_path)\n",
    "        f.write(\"__________________________________________________________\\n\")\n",
    "        f.write(\"levenshtein_similarity_result: \\n\")\n",
    "        f.write(str(levenshtein_similarity_result) + '\\n')\n",
    "        f.write(\"__________________________________________________________\\n\\n\\n\")\n",
    "        print(levenshtein_similarity_result)\n",
    "\n",
    "        jaccard_similarity_result = jaccard_similarity(file1_path, file2_path)\n",
    "        f.write(\"__________________________________________________________\\n\")\n",
    "        f.write(\"jaccard_similarity_result: \\n\")\n",
    "        f.write(str(jaccard_similarity_result) + '\\n')\n",
    "        f.write(\"__________________________________________________________\\n\\n\\n\")\n",
    "        print(jaccard_similarity_result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
